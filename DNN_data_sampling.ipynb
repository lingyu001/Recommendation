{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:53:55.498238Z",
     "start_time": "2023-04-07T13:53:55.464609Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:53:59.008679Z",
     "start_time": "2023-04-07T13:53:55.683329Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from ast import literal_eval\n",
    "\n",
    "from db_connectors.load import bigquery_reader\n",
    "from db_connectors.postprocessing import bigquery_writer\n",
    "\n",
    "# from notebooks.env import *\n",
    "from notebooks.env_prod import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:53:59.059671Z",
     "start_time": "2023-04-07T13:53:59.011073Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mikvpc-prod-service-com',\n",
       " '/Users/LINGYU1/work/repo/recommender/sa-rec-dataproc-2c-prd.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_project_id, json_key_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:53:59.164328Z",
     "start_time": "2023-04-07T13:53:59.061169Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:55:46.397011Z",
     "start_time": "2023-04-07T13:55:46.241470Z"
    }
   },
   "outputs": [],
   "source": [
    "top_user_num = 2000\n",
    "query = f\"\"\"\n",
    "\n",
    "\n",
    "-- combine mik_sales with view data\n",
    "-- just pick top 2000 user first\n",
    "\n",
    "WITH cte1 AS (\n",
    "  SELECT\n",
    "    user_id,\n",
    "    COUNT(trans_date) AS num_trans\n",
    "  FROM `Data_Infra_Eng.mik_sales`\n",
    "  WHERE data_source = \"MIK\"\n",
    "    AND trans_date BETWEEN '2023-01-24' AND '2023-02-27'\n",
    "  GROUP BY user_id\n",
    "  ORDER BY num_trans DESC\n",
    "  LIMIT {top_user_num}\n",
    "), cte2 AS (\n",
    "\n",
    "  SELECT \n",
    "    t1.user_id, \n",
    "    t1.sku_number, \n",
    "    t1.qty, \n",
    "    t1.trans_date,\n",
    "    t1.created_time,\n",
    "    t1.data_source,\n",
    "    t2.full_taxonomy_path as category_path,\n",
    "    ARRAY_AGG(t1.sku_number) --IFNULL(t2.sku_number, \"na\")\n",
    "      OVER (\n",
    "        PARTITION BY t1.user_id \n",
    "        ORDER BY t1.trans_date, t1.created_time ASC\n",
    "        ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "      ) AS sku_purchase_seq,\n",
    "    ARRAY_AGG(IFNULL(t2.full_taxonomy_path, \"na\")) \n",
    "      OVER (\n",
    "        PARTITION BY t1.user_id \n",
    "        ORDER BY t1.trans_date, t1.created_time ASC\n",
    "        ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "      ) AS category_path_purchase_seq\n",
    "  FROM `Data_Infra_Eng.mik_sales` t1\n",
    "  LEFT JOIN `Data_Infra_Eng.mik_item` t2\n",
    "    ON t1.sku_number = t2.sku_number\n",
    "  WHERE data_source = \"MIK\"\n",
    "    AND trans_date BETWEEN '2023-01-24' AND '2023-02-27'\n",
    "    -- AND t1.user_id IN (SELECT user_id FROM cte1)\n",
    "  ORDER BY user_id, trans_date, created_time ASC\n",
    "), cte3 AS (\n",
    "SELECT\n",
    "  user_id,\n",
    "  APPROX_TOP_COUNT(geo_country, 1) AS geo_country,\n",
    "  APPROX_TOP_COUNT(geo_region, 1) AS geo_region,\n",
    "  APPROX_TOP_COUNT(geo_city, 1) AS geo_city,\n",
    "  APPROX_TOP_COUNT(geo_zipcode, 1) AS geo_zipcode,\n",
    "  APPROX_TOP_COUNT(platform, 1) AS platform,\n",
    "FROM`atomic.events`\n",
    "WHERE derived_tstamp BETWEEN '2023-01-24' AND '2023-02-27'\n",
    "    -- AND user_id IN (SELECT CAST(user_id AS STRING) FROM cte1)\n",
    "GROUP BY user_id  \n",
    "\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  cte2.*,\n",
    "  cte3.geo_country,\n",
    "  cte3.geo_region,\n",
    "  cte3.geo_city,\n",
    "  cte3.geo_zipcode,\n",
    "  cte3.platform,\n",
    "  t.*\n",
    "FROM cte2\n",
    "LEFT JOIN cte3\n",
    "  ON CAST(cte2.user_id AS STRING) = cte3.user_id\n",
    "LEFT JOIN `Data_Infra_Eng.user_behavior` t\n",
    "  ON CAST(cte2.user_id AS STRING)= t.user_id\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:02:05.970037Z",
     "start_time": "2023-04-07T13:55:50.441485Z"
    }
   },
   "outputs": [],
   "source": [
    "df = bigquery_reader(\n",
    "        project_id=bq_project_id, json_credentials_path=json_key_path,\n",
    "        query_string=query\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:03:00.627561Z",
     "start_time": "2023-04-07T14:02:05.977167Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hk/mzn43h_d1p34twb9hw968f7r0000gr/T/ipykernel_18753/858920441.py:3: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  df['geo_country'] = df['geo_country'].apply(lambda x: x[0]['value'] if x else None)\n",
      "/var/folders/hk/mzn43h_d1p34twb9hw968f7r0000gr/T/ipykernel_18753/858920441.py:4: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  df['geo_region'] = df['geo_region'].apply(lambda x: x[0]['value'] if x else None)\n",
      "/var/folders/hk/mzn43h_d1p34twb9hw968f7r0000gr/T/ipykernel_18753/858920441.py:5: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  df['geo_city'] = df['geo_city'].apply(lambda x: x[0]['value'] if x else None)\n",
      "/var/folders/hk/mzn43h_d1p34twb9hw968f7r0000gr/T/ipykernel_18753/858920441.py:6: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  df['geo_zipcode'] = df['geo_zipcode'].apply(lambda x: x[0]['value'] if x else None)\n",
      "/var/folders/hk/mzn43h_d1p34twb9hw968f7r0000gr/T/ipykernel_18753/858920441.py:7: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  df['platform'] = df['platform'].apply(lambda x: x[0]['value'] if x else None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        df shape: (2039014, 17), user number: 235883, \n",
      "        avg trans per user: 8.644175290292221, \n",
      "        item number: 68644\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "df = df[df['user_id_1'].notna()].reset_index(drop=True)\n",
    "df['sku_view_sequence'] = df['user_behavior'].apply(lambda x: np.array([y['item'] for y in x]))\n",
    "df['geo_country'] = df['geo_country'].apply(lambda x: x[0]['value'] if x else None)\n",
    "df['geo_region'] = df['geo_region'].apply(lambda x: x[0]['value'] if x else None)\n",
    "df['geo_city'] = df['geo_city'].apply(lambda x: x[0]['value'] if x else None)\n",
    "df['geo_zipcode'] = df['geo_zipcode'].apply(lambda x: x[0]['value'] if x else None)\n",
    "df['platform'] = df['platform'].apply(lambda x: x[0]['value'] if x else None)\n",
    "print(f\"\"\"\n",
    "        df shape: {df.shape}, user number: {df['user_id'].nunique()}, \n",
    "        avg trans per user: {df.groupby('user_id').size().mean()}, \n",
    "        item number: {df['sku_number'].nunique()}\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:03:00.887386Z",
     "start_time": "2023-04-07T14:03:00.634681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2023-01-24 00:00:00'), Timestamp('2023-02-27 00:00:00'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['trans_date'].min(),df['trans_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:06:13.339477Z",
     "start_time": "2023-04-07T14:06:10.515486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.039014e+06\n",
       "mean     1.383778e+01\n",
       "std      3.578328e+01\n",
       "min      1.000000e+00\n",
       "25%      2.000000e+00\n",
       "50%      5.000000e+00\n",
       "75%      1.300000e+01\n",
       "max      1.886000e+03\n",
       "Name: sku_view_sequence, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sku_view_sequence'].apply(lambda x: len(x)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:06:14.923025Z",
     "start_time": "2023-04-07T14:06:13.392423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count    2.039014e+06\n",
       " mean     7.519160e+00\n",
       " std      1.590276e+01\n",
       " min      0.000000e+00\n",
       " 25%      1.000000e+00\n",
       " 50%      3.000000e+00\n",
       " 75%      8.000000e+00\n",
       " max      4.030000e+02\n",
       " Name: sku_purchase_seq, dtype: float64,\n",
       " count    2.039014e+06\n",
       " mean     7.519160e+00\n",
       " std      1.590276e+01\n",
       " min      0.000000e+00\n",
       " 25%      1.000000e+00\n",
       " 50%      3.000000e+00\n",
       " 75%      8.000000e+00\n",
       " max      4.030000e+02\n",
       " Name: category_path_purchase_seq, dtype: float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sku_purchase_seq'].apply(lambda x: len(x)).describe(), df['category_path_purchase_seq'].apply(lambda x: len(x)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:06:33.966019Z",
     "start_time": "2023-04-07T14:06:33.857212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>sku_number</th>\n",
       "      <th>qty</th>\n",
       "      <th>trans_date</th>\n",
       "      <th>created_time</th>\n",
       "      <th>data_source</th>\n",
       "      <th>category_path</th>\n",
       "      <th>sku_purchase_seq</th>\n",
       "      <th>category_path_purchase_seq</th>\n",
       "      <th>geo_country</th>\n",
       "      <th>geo_region</th>\n",
       "      <th>geo_city</th>\n",
       "      <th>geo_zipcode</th>\n",
       "      <th>platform</th>\n",
       "      <th>user_id_1</th>\n",
       "      <th>user_behavior</th>\n",
       "      <th>sku_view_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36979975</td>\n",
       "      <td>10532558</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>2023-01-30 01:17:00</td>\n",
       "      <td>MIK</td>\n",
       "      <td>root//Shop Categories//Craft Machines//Diecutt...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>NH</td>\n",
       "      <td>Hudson</td>\n",
       "      <td>03051</td>\n",
       "      <td>mob</td>\n",
       "      <td>36979975</td>\n",
       "      <td>[{'behavior': 'item_view', 'item': '10547287',...</td>\n",
       "      <td>[10547287, M10498465, M20001973]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36979975</td>\n",
       "      <td>10519524</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>2023-01-30 01:17:00</td>\n",
       "      <td>MIK</td>\n",
       "      <td>root//Shop Categories//Craft Machines//Siser//...</td>\n",
       "      <td>[10532558]</td>\n",
       "      <td>[root//Shop Categories//Craft Machines//Diecut...</td>\n",
       "      <td>US</td>\n",
       "      <td>NH</td>\n",
       "      <td>Hudson</td>\n",
       "      <td>03051</td>\n",
       "      <td>mob</td>\n",
       "      <td>36979975</td>\n",
       "      <td>[{'behavior': 'item_view', 'item': '10547287',...</td>\n",
       "      <td>[10547287, M10498465, M20001973]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id sku_number  qty trans_date        created_time data_source  \\\n",
       "0  36979975   10532558    5 2023-01-30 2023-01-30 01:17:00         MIK   \n",
       "1  36979975   10519524    2 2023-01-30 2023-01-30 01:17:00         MIK   \n",
       "\n",
       "                                       category_path sku_purchase_seq  \\\n",
       "0  root//Shop Categories//Craft Machines//Diecutt...               []   \n",
       "1  root//Shop Categories//Craft Machines//Siser//...       [10532558]   \n",
       "\n",
       "                          category_path_purchase_seq geo_country geo_region  \\\n",
       "0                                                 []          US         NH   \n",
       "1  [root//Shop Categories//Craft Machines//Diecut...          US         NH   \n",
       "\n",
       "  geo_city geo_zipcode platform user_id_1  \\\n",
       "0   Hudson       03051      mob  36979975   \n",
       "1   Hudson       03051      mob  36979975   \n",
       "\n",
       "                                       user_behavior  \\\n",
       "0  [{'behavior': 'item_view', 'item': '10547287',...   \n",
       "1  [{'behavior': 'item_view', 'item': '10547287',...   \n",
       "\n",
       "                  sku_view_sequence  \n",
       "0  [10547287, M10498465, M20001973]  \n",
       "1  [10547287, M10498465, M20001973]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:06:39.319098Z",
     "start_time": "2023-04-07T14:06:39.265886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'sku_number', 'qty', 'trans_date', 'created_time',\n",
       "       'data_source', 'category_path', 'sku_purchase_seq',\n",
       "       'category_path_purchase_seq', 'geo_country', 'geo_region', 'geo_city',\n",
       "       'geo_zipcode', 'platform', 'user_id_1', 'user_behavior',\n",
       "       'sku_view_sequence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:11:07.731036Z",
     "start_time": "2023-04-07T14:06:53.415030Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_pickle('/Users/LINGYU1/work/localspace/data/mik_dnn_model_02222023/df_raw_full_20230227.sav')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reuse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/Users/LINGYU1/work/localspace/data/mik_dnn_model_02222023/df_raw_full_20230227.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load data func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T19:29:01.910012Z",
     "start_time": "2023-03-13T19:29:01.852303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_sale_view_data(days, top_user_num):\n",
    "    query = f\"\"\"\n",
    "\n",
    "    -- combine mik_sales with view data\n",
    "    -- just pick top 200 user first\n",
    "    WITH cte1 AS (\n",
    "      SELECT\n",
    "        user_id,\n",
    "        COUNT(trans_date) AS num_trans\n",
    "      FROM `Data_Infra_Eng.mik_sales`\n",
    "      WHERE data_source = \"MIK\"\n",
    "        AND DATE_DIFF(CURRENT_DATE(), trans_date, DAY) < {days}\n",
    "      GROUP BY user_id\n",
    "      ORDER BY num_trans DESC\n",
    "      LIMIT {top_user_num}\n",
    "    ), cte2 AS (\n",
    "\n",
    "      SELECT \n",
    "        t1.user_id, \n",
    "        t1.sku_number, \n",
    "        t1.qty, \n",
    "        t1.trans_date,\n",
    "        t1.created_time,\n",
    "        t1.data_source,\n",
    "        t2.full_taxonomy_path as category_path,\n",
    "        ARRAY_AGG(t1.sku_number) --IFNULL(t2.sku_number, \"na\")\n",
    "          OVER (\n",
    "            PARTITION BY t1.user_id \n",
    "            ORDER BY t1.trans_date, t1.created_time ASC\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "          ) AS sku_purchase_seq,\n",
    "        ARRAY_AGG(IFNULL(t2.full_taxonomy_path, \"na\")) \n",
    "          OVER (\n",
    "            PARTITION BY t1.user_id \n",
    "            ORDER BY t1.trans_date, t1.created_time ASC\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "          ) AS category_path_purchase_seq\n",
    "      FROM `Data_Infra_Eng.mik_sales` t1\n",
    "      LEFT JOIN `Data_Infra_Eng.mik_item` t2\n",
    "        ON t1.sku_number = t2.sku_number\n",
    "      WHERE data_source = \"MIK\"\n",
    "        AND DATE_DIFF(CURRENT_DATE(), trans_date, DAY) < {days} \n",
    "        AND t1.user_id IN (SELECT user_id FROM cte1)\n",
    "      ORDER BY user_id, trans_date, created_time ASC\n",
    "    )\n",
    "    SELECT\n",
    "      *\n",
    "    FROM cte2 t1\n",
    "    LEFT JOIN `Data_Infra_Eng.user_behavior` t2\n",
    "      ON CAST(t1.user_id AS STRING) = t2.user_id\n",
    "    ;\n",
    "    \"\"\"\n",
    "    df = bigquery_reader(\n",
    "            project_id=bq_project_id, json_credentials_path=json_key_path,\n",
    "            query_string=query\n",
    "        )\n",
    "    df = df[df['user_id_1'].notna()].reset_index(drop=True)\n",
    "    df['sku_view_sequence'] = df['user_behavior'].apply(lambda x: np.array([y['item'] for y in x]))\n",
    "    print(f\"\"\"\n",
    "            df shape: {df.shape}, user number: {df['user_id'].nunique()}, \n",
    "            avg trans per user: {df.groupby('user_id').size().mean()}, \n",
    "            item number: {df['sku_number'].nunique()}\n",
    "            \"\"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = bigquery_reader(\n",
    "        project_id=bq_project_id, json_credentials_path=json_key_path,\n",
    "        query_string=query\n",
    "    )\n",
    "df = df[df['user_id_1'].notna()].reset_index(drop=True)\n",
    "df['sku_view_sequence'] = df['user_behavior'].apply(lambda x: np.array([y['item'] for y in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T16:26:30.808426Z",
     "start_time": "2023-03-10T16:26:17.168053Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = get_sale_view_data(35, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T16:26:30.862509Z",
     "start_time": "2023-03-10T16:26:30.809985Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67624, 12), 179, 377.7877094972067, 8183)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df['user_id'].nunique(), df.groupby('user_id').size().mean(), df['sku_number'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T17:01:39.683541Z",
     "start_time": "2023-02-27T17:01:38.626359Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/Users/LINGYU1/work/localspace/data/mik_dnn_model_02222023/df_sales_raw_20230310.pickle\", \"wb\") as f: \n",
    "    pickle.dump(df, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T16:16:49.426392Z",
     "start_time": "2023-02-27T16:16:36.994724Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[['user_id', 'sku_number', 'trans_date', 'created_time',\n",
    "    'category_path', \n",
    "    'sku_purchase_seq', 'category_path_purchase_seq', 'sku_view_sequence']]\\\n",
    "    .to_csv(\"/Users/LINGYU1/work/localspace/data/mik_dnn_model_02222023/mik_sales_views_20230227.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T21:44:38.128218Z",
     "start_time": "2023-04-06T21:44:36.928117Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41486, 8), 181)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sp = pd.read_csv(\"/Users/LINGYU1/work/localspace/data/mik_dnn_model_02222023/mik_sales_views_20230227.csv\")\n",
    "df_sp.shape, df_sp.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T20:37:52.412191Z",
     "start_time": "2023-04-06T20:37:52.339221Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2023-01-24', '2023-02-27')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sp['trans_date'].min(), df_sp['trans_date'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T15:13:16.461297Z",
     "start_time": "2023-04-07T15:13:15.803941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:13:11.187016Z",
     "start_time": "2023-04-07T14:13:08.726448Z"
    }
   },
   "outputs": [],
   "source": [
    "candidate_sku = df[['sku_number','category_path']].drop_duplicates()\n",
    "negsample_ratio = 1\n",
    "SEQ_LEN = 50\n",
    "# neg_list = np.random.choice(candidate_set, size=df.shape[0] * negsample_ratio, replace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:13:23.058180Z",
     "start_time": "2023-04-07T14:13:23.005078Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_negative_sample(data, candidate_item, negsample_ratio):\n",
    "    # get positive sample data\n",
    "    df_pos = data.copy()\n",
    "    df_pos['label'] = 1\n",
    "    \n",
    "    # create negative data\n",
    "    df_neg = pd.concat([df_pos.copy()] * negsample_ratio, ignore_index=True)\n",
    "    df_neg['label'] = 0\n",
    "    # negative sampling\n",
    "    neg_sku = candidate_item[~candidate_item['sku_number'].isin(df_pos['sku_number'])]\\\n",
    "                .sample(df_pos.shape[0] * negsample_ratio)\n",
    "    df_neg['sku_number'] = neg_sku['sku_number'].values\n",
    "    df_neg['category_path'] = neg_sku['category_path'].values\n",
    "    \n",
    "    return pd.concat([df_pos, df_neg], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:13:24.275763Z",
     "start_time": "2023-04-07T14:13:24.217106Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_input_data(df, negsample_ratio, seq_len):\n",
    "    # get candidate items and categories\n",
    "    candidate_sku = df[['sku_number','category_path']].drop_duplicates()\n",
    "    # group by user_id\n",
    "    user_group = df.groupby('user_id')\n",
    "    # negative sampling for each user group\n",
    "    df_res = []\n",
    "    for user_id, data in user_group:\n",
    "        # first refine sequence len to < seq_len\n",
    "        for col in ['sku_purchase_seq','category_path_purchase_seq','sku_view_sequence']:\n",
    "            data[col] =  data[col].apply(lambda x: x[0:seq_len])\n",
    "#             data[col] = data[col].apply(lambda x: np.lib.pad(x, \n",
    "#                                                              (seq_len - x.shape[0],0), \n",
    "#                                                              'constant', \n",
    "#                                                              constant_values=('na')))        \n",
    "        # create negative sample and combine with positive sample        \n",
    "        df_sp = create_negative_sample(data = data, candidate_item = candidate_sku, negsample_ratio = negsample_ratio)\n",
    "        df_res.append(df_sp)\n",
    "    df_res = pd.concat(df_res).reset_index(drop=True)\n",
    "    df_res['seq_len'] = seq_len\n",
    "    return df_res[[\n",
    "        'user_id', 'sku_number','category_path', 'trans_date', 'created_time',\n",
    "        'sku_purchase_seq','category_path_purchase_seq','sku_view_sequence', 'seq_len',\n",
    "        'geo_country', 'geo_region', 'geo_city','geo_zipcode', 'platform', \n",
    "        'label'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:47:07.136657Z",
     "start_time": "2023-04-07T14:13:28.048510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4078028, 15)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input = gen_input_data(df, 1, 50)\n",
    "df_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:49:14.214380Z",
     "start_time": "2023-04-07T14:49:14.031921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4078028.0\n",
       "mean           0.5\n",
       "std            0.5\n",
       "min            0.0\n",
       "25%            0.0\n",
       "50%            0.5\n",
       "75%            1.0\n",
       "max            1.0\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input.label.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:48:55.182491Z",
     "start_time": "2023-04-07T14:48:55.126816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>sku_number</th>\n",
       "      <th>category_path</th>\n",
       "      <th>trans_date</th>\n",
       "      <th>created_time</th>\n",
       "      <th>sku_purchase_seq</th>\n",
       "      <th>category_path_purchase_seq</th>\n",
       "      <th>sku_view_sequence</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>geo_country</th>\n",
       "      <th>geo_region</th>\n",
       "      <th>geo_city</th>\n",
       "      <th>geo_zipcode</th>\n",
       "      <th>platform</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1280791</td>\n",
       "      <td>D516375S</td>\n",
       "      <td>root//Shop Categories//Crafts &amp; Hobbies//Wood ...</td>\n",
       "      <td>2023-01-26</td>\n",
       "      <td>2023-01-26 13:23:23</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[MP221283]</td>\n",
       "      <td>50</td>\n",
       "      <td>US</td>\n",
       "      <td>MD</td>\n",
       "      <td>Leonardtown</td>\n",
       "      <td>20650</td>\n",
       "      <td>web</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1280791</td>\n",
       "      <td>D516375S</td>\n",
       "      <td>root//Shop Categories//Crafts &amp; Hobbies//Wood ...</td>\n",
       "      <td>2023-01-26</td>\n",
       "      <td>2023-01-26 13:23:23</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[10709269, MP221283, 10709269, 809168938375905...</td>\n",
       "      <td>50</td>\n",
       "      <td>US</td>\n",
       "      <td>MD</td>\n",
       "      <td>Leonardtown</td>\n",
       "      <td>20650</td>\n",
       "      <td>web</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id sku_number                                      category_path  \\\n",
       "0  1280791   D516375S  root//Shop Categories//Crafts & Hobbies//Wood ...   \n",
       "1  1280791   D516375S  root//Shop Categories//Crafts & Hobbies//Wood ...   \n",
       "\n",
       "  trans_date        created_time sku_purchase_seq category_path_purchase_seq  \\\n",
       "0 2023-01-26 2023-01-26 13:23:23               []                         []   \n",
       "1 2023-01-26 2023-01-26 13:23:23               []                         []   \n",
       "\n",
       "                                   sku_view_sequence  seq_len geo_country  \\\n",
       "0                                         [MP221283]       50          US   \n",
       "1  [10709269, MP221283, 10709269, 809168938375905...       50          US   \n",
       "\n",
       "  geo_region     geo_city geo_zipcode platform  label  \n",
       "0         MD  Leonardtown       20650      web      1  \n",
       "1         MD  Leonardtown       20650      web      1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:51:00.750897Z",
     "start_time": "2023-04-07T14:49:34.769295Z"
    }
   },
   "outputs": [],
   "source": [
    "df_input.to_pickle('/Users/LINGYU1/work/localspace/data/mik_dnn_model_02222023/df_input_notencode_full_20230227.sav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T16:44:54.825322Z",
     "start_time": "2023-03-10T16:44:54.776389Z"
    }
   },
   "outputs": [],
   "source": [
    "# import multiprocessing as mp\n",
    "\n",
    "# def process_chunk(chunk, candidate_sku, negsample_ratio, seq_len):\n",
    "#     # group by user_id\n",
    "#     user_group = chunk.groupby('user_id')\n",
    "#     # negative sampling for each user group\n",
    "#     df_res = []\n",
    "#     for user_id, data in user_group:\n",
    "#         # first refine sequence len to < seq_len\n",
    "#         for col in ['sku_purchase_seq','category_path_purchase_seq','sku_view_sequence']:\n",
    "#             data[col] =  data[col].apply(lambda x: x[0:seq_len])\n",
    "#         # create negative sample and combine with positive sample        \n",
    "#         df_sp = create_negative_sample(data = data, candidate_item = candidate_sku, negsample_ratio = negsample_ratio)\n",
    "#         df_res.append(df_sp)\n",
    "#     df_res = pd.concat(df_res)\n",
    "#     df_res['seq_len'] = seq_len\n",
    "#     return df_res\n",
    "\n",
    "# def gen_input_data_parallel(df, negsample_ratio, seq_len, num_processes=mp.cpu_count()):\n",
    "#     # get candidate items and categories\n",
    "#     candidate_sku = df[['sku_number','category_path']].drop_duplicates()\n",
    "    \n",
    "#     # split data into chunks\n",
    "#     chunks = np.array_split(df, num_processes)\n",
    "    \n",
    "#     # create pool of processes\n",
    "#     with mp.Pool(processes=num_processes) as pool:\n",
    "#         # process each chunk using a separate process\n",
    "#         results = [pool.apply_async(process_chunk, args=(chunk, candidate_sku, negsample_ratio, seq_len)) for chunk in chunks]\n",
    "#         # collect the results from all processes\n",
    "#         df_res = pd.concat([result.get() for result in results]).reset_index(drop=True)\n",
    "    \n",
    "#     return df_res[[\n",
    "#         'user_id', 'sku_number','category_path', 'trans_date', 'created_time',\n",
    "#         'sku_purchase_seq','category_path_purchase_seq','sku_view_sequence', 'seq_len',\n",
    "#         'label'\n",
    "#     ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_input = gen_input_data_parallel(df, 1, 50)\n",
    "# df_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:52:18.397584Z",
     "start_time": "2023-04-07T14:52:16.895890Z"
    }
   },
   "outputs": [],
   "source": [
    "df_input_copy = df_input.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T21:12:45.188232Z",
     "start_time": "2023-04-06T21:12:45.129849Z"
    }
   },
   "outputs": [],
   "source": [
    "df_input = df_input_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:52:21.074407Z",
     "start_time": "2023-04-07T14:52:20.976369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>sku_number</th>\n",
       "      <th>category_path</th>\n",
       "      <th>trans_date</th>\n",
       "      <th>created_time</th>\n",
       "      <th>sku_purchase_seq</th>\n",
       "      <th>category_path_purchase_seq</th>\n",
       "      <th>sku_view_sequence</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>geo_country</th>\n",
       "      <th>geo_region</th>\n",
       "      <th>geo_city</th>\n",
       "      <th>geo_zipcode</th>\n",
       "      <th>platform</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1280791</td>\n",
       "      <td>D516375S</td>\n",
       "      <td>root//Shop Categories//Crafts &amp; Hobbies//Wood ...</td>\n",
       "      <td>2023-01-26</td>\n",
       "      <td>2023-01-26 13:23:23</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[MP221283]</td>\n",
       "      <td>50</td>\n",
       "      <td>US</td>\n",
       "      <td>MD</td>\n",
       "      <td>Leonardtown</td>\n",
       "      <td>20650</td>\n",
       "      <td>web</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1280791</td>\n",
       "      <td>D516375S</td>\n",
       "      <td>root//Shop Categories//Crafts &amp; Hobbies//Wood ...</td>\n",
       "      <td>2023-01-26</td>\n",
       "      <td>2023-01-26 13:23:23</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[10709269, MP221283, 10709269, 809168938375905...</td>\n",
       "      <td>50</td>\n",
       "      <td>US</td>\n",
       "      <td>MD</td>\n",
       "      <td>Leonardtown</td>\n",
       "      <td>20650</td>\n",
       "      <td>web</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id sku_number                                      category_path  \\\n",
       "0  1280791   D516375S  root//Shop Categories//Crafts & Hobbies//Wood ...   \n",
       "1  1280791   D516375S  root//Shop Categories//Crafts & Hobbies//Wood ...   \n",
       "\n",
       "  trans_date        created_time sku_purchase_seq category_path_purchase_seq  \\\n",
       "0 2023-01-26 2023-01-26 13:23:23               []                         []   \n",
       "1 2023-01-26 2023-01-26 13:23:23               []                         []   \n",
       "\n",
       "                                   sku_view_sequence  seq_len geo_country  \\\n",
       "0                                         [MP221283]       50          US   \n",
       "1  [10709269, MP221283, 10709269, 809168938375905...       50          US   \n",
       "\n",
       "  geo_region     geo_city geo_zipcode platform  label  \n",
       "0         MD  Leonardtown       20650      web      1  \n",
       "1         MD  Leonardtown       20650      web      1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dumb encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T21:12:56.615292Z",
     "start_time": "2023-04-06T21:12:56.560387Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'sku_number', 'category_path', 'trans_date', 'created_time',\n",
       "       'sku_purchase_seq', 'category_path_purchase_seq', 'sku_view_sequence',\n",
       "       'seq_len', 'geo_country', 'geo_region', 'geo_city', 'geo_zipcode',\n",
       "       'platform', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T21:12:56.780466Z",
     "start_time": "2023-04-06T21:12:56.730727Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T21:12:58.013866Z",
     "start_time": "2023-04-06T21:12:57.955301Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def label_transform(lbe, x):\n",
    "    try:\n",
    "        return lbe.transform(x) + 1 # add one to all the encoded categories labels\n",
    "    except:\n",
    "        return np.array([])\n",
    "    \n",
    "def encode_features_old(df_input):\n",
    "    # store original item id and user id\n",
    "    df_input['sku_number_org'] = df_input['sku_number']\n",
    "    df_input['user_id_org'] = df_input['user_id']\n",
    "    \n",
    "    # specify features and sequence features\n",
    "    sparse_features = [\n",
    "        'sku_number', 'category_path',\n",
    "        'user_id','geo_country', 'geo_region', \n",
    "        'geo_city', 'geo_zipcode','platform'\n",
    "    ]\n",
    "    seq_sparse_feature = ['sku_purchase_seq','category_path_purchase_seq','sku_view_sequence']\n",
    "    \n",
    "    # get full set of item and category\n",
    "    full_item_set = np.append(\n",
    "        np.unique(\n",
    "            np.concatenate(\n",
    "                (\n",
    "                    df_input['sku_number'].values,  # all sku in sales\n",
    "                    df_input['sku_view_sequence'].explode().values # all sku in views\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        , 'na')\n",
    "    full_cat_set = np.append(df_input['category_path'].unique(), 'na')\n",
    "    \n",
    "    # fit and transform features\n",
    "    for feature in sparse_features:\n",
    "        # need to store sku encoder\n",
    "        if feature == 'sku_number':\n",
    "            lbe_sku = LabelEncoder()\n",
    "            lbe_sku.fit(full_item_set)\n",
    "            df_input[feature] = lbe_sku.transform(df_input[feature]) + 1 # add one to all the encoded categories labels\n",
    "        # need to store\n",
    "        elif feature == 'category_path':\n",
    "            lbe_cat = LabelEncoder()\n",
    "            lbe_cat.fit(full_cat_set)\n",
    "            df_input[feature] = lbe_cat.transform(df_input[feature]) + 1 # add one to all the encoded categories labels\n",
    "        else:\n",
    "            lbe = LabelEncoder()\n",
    "            df_input[feature] = lbe.fit_transform(df_input[feature]) + 1 # add one to all the encoded categories labels \n",
    "    # trasnform sequence features\n",
    "    for feature in seq_sparse_feature:\n",
    "        if feature == 'sku_purchase_seq' or feature == 'sku_view_sequence':\n",
    "            df_input[feature] = df_input[feature].apply(lambda x: label_transform(lbe_sku, x))\n",
    "\n",
    "        elif feature == 'category_path_purchase_seq':\n",
    "            df_input[feature] = df_input[feature].apply(lambda x: label_transform(lbe_cat, x))\n",
    "    \n",
    "    # get feature index table\n",
    "    feature_max_idx = {}\n",
    "    for feature in sparse_features:\n",
    "        feature_max_idx[feature] = df_input[feature].max() + 1\n",
    "    \n",
    "    return df_input, feature_max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-06T21:13:18.810Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_input, feature_max_idx = encode_features_old(df_input)\n",
    "df_input.shape, len(feature_max_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T20:47:49.306173Z",
     "start_time": "2023-04-06T20:47:48.711691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbe_sku = LabelEncoder()\n",
    "lbe_sku.fit(full_item_set)\n",
    "lbe_cat = LabelEncoder()\n",
    "lbe_cat.fit(full_cat_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T20:58:39.603759Z",
     "start_time": "2023-04-06T20:58:39.538173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12590,), (817,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_item_set = lbe_sku.transform(full_item_set) + 1 # +1 to remove 0, 0 leave it for missing value\n",
    "encoded_cat_set = lbe_cat.transform(full_cat_set) + 1 # +1 to remove 0, 0 leave it for missing value\n",
    "encoded_item_set.shape, encoded_cat_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T20:59:19.632560Z",
     "start_time": "2023-04-06T20:59:19.574156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12590, 817)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sku_dict = {full_item_set[i]: encoded_item_set[i] for i in range(len(full_item_set))}\n",
    "cat_dict = {full_cat_set[i]: encoded_cat_set[i] for i in range(len(full_cat_set))}\n",
    "len(sku_dict), len(cat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T21:02:04.050311Z",
     "start_time": "2023-04-06T21:02:03.996205Z"
    }
   },
   "outputs": [],
   "source": [
    "sparse_features = [\n",
    "        'sku_number', 'category_path',\n",
    "        'user_id','geo_country', 'geo_region', \n",
    "        'geo_city', 'geo_zipcode','platform'\n",
    "]\n",
    "seq_sparse_feature = ['sku_purchase_seq','category_path_purchase_seq','sku_view_sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T21:02:04.508504Z",
     "start_time": "2023-04-06T21:02:04.222410Z"
    }
   },
   "outputs": [],
   "source": [
    " # fit and transform features\n",
    "for feature in sparse_features:\n",
    "    # need to store sku encoder\n",
    "    if feature == 'sku_number':\n",
    "        df_input[feature] = lbe_sku.transform(df_input[feature]) + 1 # add one to all the encoded categories labels\n",
    "    # need to store\n",
    "    elif feature == 'category_path':\n",
    "        df_input[feature] = lbe_cat.transform(df_input[feature]) + 1 # add one to all the encoded categories labels\n",
    "    else:\n",
    "        lbe = LabelEncoder()\n",
    "        df_input[feature] = lbe.fit_transform(df_input[feature]) + 1 # add one to all the encoded categories labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T21:05:05.477346Z",
     "start_time": "2023-04-06T21:05:02.619777Z"
    }
   },
   "outputs": [],
   "source": [
    "# encode sequence features\n",
    "for feature in seq_sparse_feature:\n",
    "    if feature == 'sku_purchase_seq' or feature == 'sku_view_sequence':\n",
    "        df_input[feature] = df_input[feature].apply(lambda x: np.array([sku_dict[c] for c in x]))\n",
    "\n",
    "    elif feature == 'category_path_purchase_seq':\n",
    "        df_input[feature] = df_input[feature].apply(lambda x: np.array([cat_dict[c] for c in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T21:06:41.462359Z",
     "start_time": "2023-04-06T21:06:41.403500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12590"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_item_set.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T21:07:22.316595Z",
     "start_time": "2023-04-06T21:07:22.263244Z"
    }
   },
   "outputs": [],
   "source": [
    "# get feature index table\n",
    "feature_max_idx = {}\n",
    "for feature in sparse_features:\n",
    "    if feature == 'sku_number':\n",
    "        feature_max_idx[feature] = encoded_item_set.max() + 1\n",
    "    elif feature == 'category_path':\n",
    "        feature_max_idx[feature] = encoded_cat_set.max() + 1\n",
    "    else:\n",
    "        feature_max_idx[feature] = df_input[feature].max() + 1 # plus one to the max\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:52:34.185730Z",
     "start_time": "2023-04-07T14:52:34.099520Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_features(df_input):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    # store original item id and user id\n",
    "    df_input['sku_number_org'] = df_input['sku_number']\n",
    "    df_input['user_id_org'] = df_input['user_id']\n",
    "    \n",
    "    # specify features and sequence features\n",
    "    sparse_features = [\n",
    "        'sku_number', 'category_path',\n",
    "        'user_id','geo_country', 'geo_region', \n",
    "        'geo_city', 'geo_zipcode','platform'\n",
    "    ]\n",
    "    seq_sparse_feature = ['sku_purchase_seq','category_path_purchase_seq','sku_view_sequence']\n",
    "    \n",
    "    # get full set of item and category\n",
    "    full_item_set = np.append(\n",
    "        np.unique(\n",
    "            np.concatenate(\n",
    "                (\n",
    "                    df_input['sku_number'].values,  # all sku in sales\n",
    "                    df_input['sku_view_sequence'].explode().values # all sku in views\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        , 'na')\n",
    "    full_cat_set = np.append(df_input['category_path'].unique(), 'na')\n",
    "    \n",
    "    # encode item and cat set\n",
    "    lbe_sku = LabelEncoder()\n",
    "    lbe_sku.fit(full_item_set)\n",
    "    lbe_cat = LabelEncoder()\n",
    "    lbe_cat.fit(full_cat_set)\n",
    "    encoded_item_set = lbe_sku.transform(full_item_set) + 1 # +1 to remove 0, 0 leave it for missing value\n",
    "    encoded_cat_set = lbe_cat.transform(full_cat_set) + 1 # +1 to remove 0, 0 leave it for missing value\n",
    "    \n",
    "    # create encode dict\n",
    "    sku_dict = {full_item_set[i]: encoded_item_set[i] for i in range(len(full_item_set))}\n",
    "    cat_dict = {full_cat_set[i]: encoded_cat_set[i] for i in range(len(full_cat_set))}\n",
    "    \n",
    "    \n",
    "     # fit and transform sparse features\n",
    "    for feature in sparse_features:\n",
    "        # need to store sku encoder\n",
    "        if feature == 'sku_number':\n",
    "            df_input[feature] = lbe_sku.transform(df_input[feature]) + 1 # add one to all the encoded categories labels\n",
    "        # need to store\n",
    "        elif feature == 'category_path':\n",
    "            df_input[feature] = lbe_cat.transform(df_input[feature]) + 1 # add one to all the encoded categories labels\n",
    "        else:\n",
    "            lbe = LabelEncoder()\n",
    "            df_input[feature] = lbe.fit_transform(df_input[feature]) + 1 # add one to all the encoded categories labels \n",
    "\n",
    "    # encode sequence features\n",
    "    for feature in seq_sparse_feature:\n",
    "        if feature == 'sku_purchase_seq' or feature == 'sku_view_sequence':\n",
    "            df_input[feature] = df_input[feature].apply(lambda x: np.array([sku_dict[c] for c in x]))\n",
    "        elif feature == 'category_path_purchase_seq':\n",
    "            df_input[feature] = df_input[feature].apply(lambda x: np.array([cat_dict[c] for c in x]))\n",
    "    \n",
    "    # get feature index table\n",
    "    feature_max_idx = {}\n",
    "    for feature in sparse_features:\n",
    "        if feature == 'sku_number':\n",
    "            feature_max_idx[feature] = encoded_item_set.max() + 1\n",
    "        elif feature == 'category_path':\n",
    "            feature_max_idx[feature] = encoded_cat_set.max() + 1\n",
    "        else:\n",
    "            feature_max_idx[feature] = df_input[feature].max() + 1 # plus one to the max\n",
    "    \n",
    "    return df_input, feature_max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:56:22.298178Z",
     "start_time": "2023-04-07T14:52:37.836053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4078028, 17), 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input, feature_max_idx = encode_features(df_input)\n",
    "df_input.shape, len(feature_max_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T14:59:56.710537Z",
     "start_time": "2023-04-07T14:59:56.461315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>sku_number</th>\n",
       "      <th>category_path</th>\n",
       "      <th>trans_date</th>\n",
       "      <th>created_time</th>\n",
       "      <th>sku_purchase_seq</th>\n",
       "      <th>category_path_purchase_seq</th>\n",
       "      <th>sku_view_sequence</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>geo_country</th>\n",
       "      <th>geo_region</th>\n",
       "      <th>geo_city</th>\n",
       "      <th>geo_zipcode</th>\n",
       "      <th>platform</th>\n",
       "      <th>label</th>\n",
       "      <th>sku_number_org</th>\n",
       "      <th>user_id_org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>124265</td>\n",
       "      <td>710</td>\n",
       "      <td>2023-01-26</td>\n",
       "      <td>2023-01-26 13:23:23.000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[157341]</td>\n",
       "      <td>50</td>\n",
       "      <td>86</td>\n",
       "      <td>97</td>\n",
       "      <td>3360</td>\n",
       "      <td>3101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>D516375S</td>\n",
       "      <td>1280791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>124265</td>\n",
       "      <td>710</td>\n",
       "      <td>2023-01-26</td>\n",
       "      <td>2023-01-26 13:23:23.000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[38158, 157341, 38158, 79216, 157341]</td>\n",
       "      <td>50</td>\n",
       "      <td>86</td>\n",
       "      <td>97</td>\n",
       "      <td>3360</td>\n",
       "      <td>3101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>D516375S</td>\n",
       "      <td>1280791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>30578</td>\n",
       "      <td>1744</td>\n",
       "      <td>2023-01-26</td>\n",
       "      <td>2023-01-26 13:23:23.000</td>\n",
       "      <td>[124265]</td>\n",
       "      <td>[710]</td>\n",
       "      <td>[38158, 157341, 38158, 79216, 157341]</td>\n",
       "      <td>50</td>\n",
       "      <td>86</td>\n",
       "      <td>97</td>\n",
       "      <td>3360</td>\n",
       "      <td>3101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10684625</td>\n",
       "      <td>1280791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>157341</td>\n",
       "      <td>2087</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>2023-02-21 17:51:17.774</td>\n",
       "      <td>[124265, 30578]</td>\n",
       "      <td>[710, 1744]</td>\n",
       "      <td>[157341]</td>\n",
       "      <td>50</td>\n",
       "      <td>86</td>\n",
       "      <td>97</td>\n",
       "      <td>3360</td>\n",
       "      <td>3101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>MP221283</td>\n",
       "      <td>1280791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>157341</td>\n",
       "      <td>2087</td>\n",
       "      <td>2023-02-21</td>\n",
       "      <td>2023-02-21 17:51:17.774</td>\n",
       "      <td>[124265, 30578]</td>\n",
       "      <td>[710, 1744]</td>\n",
       "      <td>[21594, 157341]</td>\n",
       "      <td>50</td>\n",
       "      <td>86</td>\n",
       "      <td>97</td>\n",
       "      <td>3360</td>\n",
       "      <td>3101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>MP221283</td>\n",
       "      <td>1280791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  sku_number  category_path trans_date            created_time  \\\n",
       "0        1      124265            710 2023-01-26 2023-01-26 13:23:23.000   \n",
       "1        1      124265            710 2023-01-26 2023-01-26 13:23:23.000   \n",
       "2        1       30578           1744 2023-01-26 2023-01-26 13:23:23.000   \n",
       "3        1      157341           2087 2023-02-21 2023-02-21 17:51:17.774   \n",
       "4        1      157341           2087 2023-02-21 2023-02-21 17:51:17.774   \n",
       "\n",
       "  sku_purchase_seq category_path_purchase_seq  \\\n",
       "0               []                         []   \n",
       "1               []                         []   \n",
       "2         [124265]                      [710]   \n",
       "3  [124265, 30578]                [710, 1744]   \n",
       "4  [124265, 30578]                [710, 1744]   \n",
       "\n",
       "                       sku_view_sequence  seq_len  geo_country  geo_region  \\\n",
       "0                               [157341]       50           86          97   \n",
       "1  [38158, 157341, 38158, 79216, 157341]       50           86          97   \n",
       "2  [38158, 157341, 38158, 79216, 157341]       50           86          97   \n",
       "3                               [157341]       50           86          97   \n",
       "4                        [21594, 157341]       50           86          97   \n",
       "\n",
       "   geo_city  geo_zipcode  platform  label sku_number_org  user_id_org  \n",
       "0      3360         3101         2      1       D516375S      1280791  \n",
       "1      3360         3101         2      1       D516375S      1280791  \n",
       "2      3360         3101         2      1       10684625      1280791  \n",
       "3      3360         3101         2      1       MP221283      1280791  \n",
       "4      3360         3101         2      1       MP221283      1280791  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T15:02:07.259720Z",
     "start_time": "2023-04-07T15:00:15.550265Z"
    }
   },
   "outputs": [],
   "source": [
    "df_input.to_pickle('/Users/LINGYU1/work/localspace/data/mik_dnn_model_02222023/df_input_full_20230227.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T16:53:26.586732Z",
     "start_time": "2023-03-10T16:53:26.534039Z"
    }
   },
   "outputs": [],
   "source": [
    "# import concurrent.futures\n",
    "\n",
    "# def encode_features(df_input):\n",
    "#     # store original item id and user id\n",
    "#     df_input['sku_number_org'] = df_input['sku_number']\n",
    "#     df_input['user_id_org'] = df_input['user_id']\n",
    "\n",
    "#     # specify features and sequence features\n",
    "#     sparse_features = ['sku_number', 'category_path', 'user_id']\n",
    "#     seq_sparse_feature = ['sku_purchase_seq','category_path_purchase_seq','sku_view_sequence']\n",
    "\n",
    "#     # get full set of item and category\n",
    "#     full_item_set = np.append(\n",
    "#         np.unique(\n",
    "#             np.concatenate(\n",
    "#                 (\n",
    "#                     df_input['sku_number'].values,  # all sku in sales\n",
    "#                     df_input['sku_view_sequence'].explode().values # all sku in views\n",
    "#                 )\n",
    "#             )\n",
    "#         )\n",
    "#         , 'na')\n",
    "#     full_cat_set = np.append(df_input['category_path'].unique(), 'na')\n",
    "\n",
    "#     # fit and transform features\n",
    "#     with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#         futures = []\n",
    "#         encoders = {}\n",
    "#         for feature in sparse_features:\n",
    "#             # need to store sku encoder\n",
    "#             if feature == 'sku_number':\n",
    "#                 encoders[feature] = LabelEncoder()\n",
    "#                 encoders[feature].fit(full_item_set)\n",
    "#             # need to store\n",
    "#             elif feature == 'category_path':\n",
    "#                 encoders[feature] = LabelEncoder()\n",
    "#                 encoders[feature].fit(full_cat_set)\n",
    "#             else:\n",
    "#                 encoders[feature] = LabelEncoder()\n",
    "#             futures.append(executor.submit(lambda feature: (feature, encoders[feature].fit_transform(df_input[feature]) + 1), feature))\n",
    "#         for future in concurrent.futures.as_completed(futures):\n",
    "#             feature, transformed = future.result()\n",
    "#             df_input[feature] = transformed\n",
    "\n",
    "#     # transform sequence features\n",
    "#     for feature in seq_sparse_feature:\n",
    "#         if feature == 'sku_purchase_seq' or feature == 'sku_view_sequence':\n",
    "#             df_input[feature] = df_input[feature].apply(lambda x: label_transform(encoders['sku_number'], x))\n",
    "\n",
    "#         elif feature == 'category_path_purchase_seq':\n",
    "#             df_input[feature] = df_input[feature].apply(lambda x: label_transform(encoders['category_path'], x))\n",
    "\n",
    "#     # get feature index table\n",
    "#     feature_max_idx = {}\n",
    "#     for feature in sparse_features:\n",
    "#         feature_max_idx[feature] = df_input[feature].max() + 1\n",
    "\n",
    "#     return df_input, feature_max_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T17:12:16.405095Z",
     "start_time": "2023-03-10T16:53:28.971162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135248, 12)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input, feature_max_idx = encode_features(df_input)\n",
    "df_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T16:52:17.666432Z",
     "start_time": "2023-03-10T16:52:17.666420Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T03:15:57.874235Z",
     "start_time": "2023-03-23T03:15:45.719299Z"
    }
   },
   "outputs": [],
   "source": [
    "df_input.to_pickle('/Users/LINGYU1/work/localspace/data/mik_dnn_model_02222023/df_input_full_20230227.sav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T19:33:00.713097Z",
     "start_time": "2023-03-23T19:33:00.273941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'sku_number', 'category_path', 'trans_date', 'created_time',\n",
       "       'sku_purchase_seq', 'category_path_purchase_seq', 'sku_view_sequence',\n",
       "       'seq_len', 'geo_country', 'geo_region', 'geo_city', 'geo_zipcode',\n",
       "       'platform', 'label', 'sku_number_org', 'user_id_org'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T19:33:33.497559Z",
     "start_time": "2023-03-23T19:33:32.008289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>sku_number</th>\n",
       "      <th>category_path</th>\n",
       "      <th>trans_date</th>\n",
       "      <th>sku_purchase_seq</th>\n",
       "      <th>category_path_purchase_seq</th>\n",
       "      <th>sku_view_sequence</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>geo_zipcode</th>\n",
       "      <th>platform</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4233</td>\n",
       "      <td>1109</td>\n",
       "      <td>2023-02-14</td>\n",
       "      <td>[8798, 12990, 13000, 13017, 13019, 3545]</td>\n",
       "      <td>[866, 251, 251, 251, 251, 1109]</td>\n",
       "      <td>[18479, 21115]</td>\n",
       "      <td>50</td>\n",
       "      <td>259</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11222</td>\n",
       "      <td>1109</td>\n",
       "      <td>2023-02-14</td>\n",
       "      <td>[8798, 12990, 13000, 13017, 13019, 3545, 4233,...</td>\n",
       "      <td>[866, 251, 251, 251, 251, 1109, 1109, 1109]</td>\n",
       "      <td>[18479, 21115]</td>\n",
       "      <td>50</td>\n",
       "      <td>259</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20938</td>\n",
       "      <td>769</td>\n",
       "      <td>2023-02-14</td>\n",
       "      <td>[8798, 12990, 13000, 13017, 13019, 3545, 4233,...</td>\n",
       "      <td>[866, 251, 251, 251, 251, 1109, 1109, 1109, 11...</td>\n",
       "      <td>[32380, 32379, 15900, 4233, 7093, 1534, 6041, ...</td>\n",
       "      <td>50</td>\n",
       "      <td>259</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1282</td>\n",
       "      <td>694</td>\n",
       "      <td>2023-02-14</td>\n",
       "      <td>[8798, 12990, 13000, 13017, 13019, 3545, 4233,...</td>\n",
       "      <td>[866, 251, 251, 251, 251, 1109, 1109, 1109, 11...</td>\n",
       "      <td>[18479, 21115]</td>\n",
       "      <td>50</td>\n",
       "      <td>259</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>21226</td>\n",
       "      <td>748</td>\n",
       "      <td>2023-02-26</td>\n",
       "      <td>[8798, 12990, 13000, 13017, 13019, 3545, 4233,...</td>\n",
       "      <td>[866, 251, 251, 251, 251, 1109, 1109, 1109, 11...</td>\n",
       "      <td>[32380, 32379, 15900, 4233, 7093, 1534, 6041, ...</td>\n",
       "      <td>50</td>\n",
       "      <td>259</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507891</th>\n",
       "      <td>1717</td>\n",
       "      <td>19196</td>\n",
       "      <td>987</td>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>[10533, 3161, 1114, 11074, 8479, 6971, 684, 13...</td>\n",
       "      <td>[35, 444, 620, 467, 170, 574, 454, 1009, 672, ...</td>\n",
       "      <td>[30210, 20458, 29148, 31856, 29796, 5079, 3367...</td>\n",
       "      <td>50</td>\n",
       "      <td>1102</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507892</th>\n",
       "      <td>1717</td>\n",
       "      <td>18194</td>\n",
       "      <td>1114</td>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>[10533, 3161, 1114, 11074, 8479, 6971, 684, 13...</td>\n",
       "      <td>[35, 444, 620, 467, 170, 574, 454, 1009, 672, ...</td>\n",
       "      <td>[28296, 2189, 20215, 8945, 23912, 30656, 19600...</td>\n",
       "      <td>50</td>\n",
       "      <td>1102</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507893</th>\n",
       "      <td>1717</td>\n",
       "      <td>16572</td>\n",
       "      <td>1147</td>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>[10533, 3161, 1114, 11074, 8479, 6971, 684, 13...</td>\n",
       "      <td>[35, 444, 620, 467, 170, 574, 454, 1009, 672, ...</td>\n",
       "      <td>[28296, 2189, 20215, 8945, 23912, 30656, 19600...</td>\n",
       "      <td>50</td>\n",
       "      <td>1102</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507894</th>\n",
       "      <td>1717</td>\n",
       "      <td>3616</td>\n",
       "      <td>240</td>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>[10533, 3161, 1114, 11074, 8479, 6971, 684, 13...</td>\n",
       "      <td>[35, 444, 620, 467, 170, 574, 454, 1009, 672, ...</td>\n",
       "      <td>[30210, 20458, 29148, 31856, 29796, 5079, 3367...</td>\n",
       "      <td>50</td>\n",
       "      <td>1102</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507895</th>\n",
       "      <td>1717</td>\n",
       "      <td>2290</td>\n",
       "      <td>450</td>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>[10533, 3161, 1114, 11074, 8479, 6971, 684, 13...</td>\n",
       "      <td>[35, 444, 620, 467, 170, 574, 454, 1009, 672, ...</td>\n",
       "      <td>[28296, 2189, 20215, 8945, 23912, 30656, 19600...</td>\n",
       "      <td>50</td>\n",
       "      <td>1102</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>507896 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  sku_number  category_path trans_date  \\\n",
       "0             1        4233           1109 2023-02-14   \n",
       "1             1       11222           1109 2023-02-14   \n",
       "2             1       20938            769 2023-02-14   \n",
       "3             1        1282            694 2023-02-14   \n",
       "4             1       21226            748 2023-02-26   \n",
       "...         ...         ...            ...        ...   \n",
       "507891     1717       19196            987 2023-02-17   \n",
       "507892     1717       18194           1114 2023-02-17   \n",
       "507893     1717       16572           1147 2023-02-17   \n",
       "507894     1717        3616            240 2023-02-17   \n",
       "507895     1717        2290            450 2023-02-17   \n",
       "\n",
       "                                         sku_purchase_seq  \\\n",
       "0                [8798, 12990, 13000, 13017, 13019, 3545]   \n",
       "1       [8798, 12990, 13000, 13017, 13019, 3545, 4233,...   \n",
       "2       [8798, 12990, 13000, 13017, 13019, 3545, 4233,...   \n",
       "3       [8798, 12990, 13000, 13017, 13019, 3545, 4233,...   \n",
       "4       [8798, 12990, 13000, 13017, 13019, 3545, 4233,...   \n",
       "...                                                   ...   \n",
       "507891  [10533, 3161, 1114, 11074, 8479, 6971, 684, 13...   \n",
       "507892  [10533, 3161, 1114, 11074, 8479, 6971, 684, 13...   \n",
       "507893  [10533, 3161, 1114, 11074, 8479, 6971, 684, 13...   \n",
       "507894  [10533, 3161, 1114, 11074, 8479, 6971, 684, 13...   \n",
       "507895  [10533, 3161, 1114, 11074, 8479, 6971, 684, 13...   \n",
       "\n",
       "                               category_path_purchase_seq  \\\n",
       "0                         [866, 251, 251, 251, 251, 1109]   \n",
       "1             [866, 251, 251, 251, 251, 1109, 1109, 1109]   \n",
       "2       [866, 251, 251, 251, 251, 1109, 1109, 1109, 11...   \n",
       "3       [866, 251, 251, 251, 251, 1109, 1109, 1109, 11...   \n",
       "4       [866, 251, 251, 251, 251, 1109, 1109, 1109, 11...   \n",
       "...                                                   ...   \n",
       "507891  [35, 444, 620, 467, 170, 574, 454, 1009, 672, ...   \n",
       "507892  [35, 444, 620, 467, 170, 574, 454, 1009, 672, ...   \n",
       "507893  [35, 444, 620, 467, 170, 574, 454, 1009, 672, ...   \n",
       "507894  [35, 444, 620, 467, 170, 574, 454, 1009, 672, ...   \n",
       "507895  [35, 444, 620, 467, 170, 574, 454, 1009, 672, ...   \n",
       "\n",
       "                                        sku_view_sequence  seq_len  \\\n",
       "0                                          [18479, 21115]       50   \n",
       "1                                          [18479, 21115]       50   \n",
       "2       [32380, 32379, 15900, 4233, 7093, 1534, 6041, ...       50   \n",
       "3                                          [18479, 21115]       50   \n",
       "4       [32380, 32379, 15900, 4233, 7093, 1534, 6041, ...       50   \n",
       "...                                                   ...      ...   \n",
       "507891  [30210, 20458, 29148, 31856, 29796, 5079, 3367...       50   \n",
       "507892  [28296, 2189, 20215, 8945, 23912, 30656, 19600...       50   \n",
       "507893  [28296, 2189, 20215, 8945, 23912, 30656, 19600...       50   \n",
       "507894  [30210, 20458, 29148, 31856, 29796, 5079, 3367...       50   \n",
       "507895  [28296, 2189, 20215, 8945, 23912, 30656, 19600...       50   \n",
       "\n",
       "        geo_zipcode  platform  label  \n",
       "0               259         2      1  \n",
       "1               259         2      1  \n",
       "2               259         2      1  \n",
       "3               259         2      1  \n",
       "4               259         2      1  \n",
       "...             ...       ...    ...  \n",
       "507891         1102         2      0  \n",
       "507892         1102         2      0  \n",
       "507893         1102         2      0  \n",
       "507894         1102         2      0  \n",
       "507895         1102         2      0  \n",
       "\n",
       "[507896 rows x 11 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input[['user_id', 'sku_number', 'category_path', 'trans_date',\n",
    "       'sku_purchase_seq', 'category_path_purchase_seq', 'sku_view_sequence',\n",
    "       'seq_len',  'geo_zipcode',\n",
    "       'platform', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T17:01:39.683541Z",
     "start_time": "2023-02-27T17:01:38.626359Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"/Users/LINGYU1/work/localspace/data/mik_dnn_model_02222023/df_input_20230227.pickle\", \"wb\") as f: \n",
    "#     pickle.dump(df_input, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T17:01:26.411793Z",
     "start_time": "2023-02-27T17:01:25.657478Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_input.to_json('/Users/LINGYU1/work/localspace/data/mik_dnn_model_02222023/df_input_20230227.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T17:08:10.946239Z",
     "start_time": "2023-02-27T17:08:08.895537Z"
    }
   },
   "outputs": [],
   "source": [
    "full_item_set = np.append(\n",
    "    np.unique(\n",
    "        np.concatenate(\n",
    "            (\n",
    "                df_input['sku_number'].values,  # all sku in sales\n",
    "                df_input['sku_view_sequence'].explode().values # all sku in views\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    , 'na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T17:08:19.624033Z",
     "start_time": "2023-02-27T17:08:19.566217Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, ..., 11035, 11036, 'na'], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_item_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T18:19:06.329436Z",
     "start_time": "2023-02-27T18:19:06.270556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df['sku_purchase_seq'][15]\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T18:19:02.604890Z",
     "start_time": "2023-02-27T18:19:02.542060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10358097', '10683360', '10403125', '10196947', '10228172'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sku_purchase_seq'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T18:13:55.777339Z",
     "start_time": "2023-02-27T18:13:55.699401Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [83]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m np\u001B[38;5;241m.\u001B[39mconcatenate([a, np\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;241m13\u001B[39m, \u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m))], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mIndexError\u001B[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "np.concatenate([a, np.zeros((13, a.shape[1]))], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T18:22:19.668599Z",
     "start_time": "2023-02-27T18:22:19.612796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na',\n",
       "       'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na',\n",
       "       'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na',\n",
       "       'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na',\n",
       "       'na', '10358097', '10683360', '10403125', '10196947', '10228172'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.lib.pad(a, (50 - a.shape[0],0), 'constant', constant_values=('na'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-24T23:30:09.414245Z",
     "start_time": "2023-02-24T23:30:08.237288Z"
    }
   },
   "outputs": [],
   "source": [
    "full_item_set = np.append(\n",
    "    np.unique(\n",
    "        np.concatenate(\n",
    "            (\n",
    "                df_input['sku_number'].values,  # all sku in sales\n",
    "                df_input['sku_view_sequence'].explode().values # all sku in views\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    , 'na')\n",
    "full_cat_set = np.append(df_input['category_path'].unique(), 'na')\n",
    "# fit and transform features\n",
    "for feature in sparse_features:\n",
    "    # need to store sku encoder\n",
    "    if feature == 'sku_number':\n",
    "        lbe_sku = LabelEncoder()\n",
    "        lbe_sku.fit(full_item_set)\n",
    "        df_input[feature] = lbe_sku.transform(df_input[feature]) + 1\n",
    "    # need to store\n",
    "    elif feature == 'category_path':\n",
    "        lbe_cat = LabelEncoder()\n",
    "        lbe_cat.fit(full_cat_set)\n",
    "        df_input[feature] = lbe_cat.transform(df_input[feature]) + 1\n",
    "    else:\n",
    "        lbe = LabelEncoder()\n",
    "        df_input[feature] = lbe.fit_transform(df_input[feature]) + 1 # add one to all the encoded categories labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-24T23:30:17.175349Z",
     "start_time": "2023-02-24T23:30:17.125168Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_input_copy['category_path_purchase_seq'][0:10].apply(lambda x: label_transform(lbe_cat, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-24T23:30:20.434416Z",
     "start_time": "2023-02-24T23:30:20.381368Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_input[feature].apply(lambda x: lbe_cat.transform(x) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-24T23:40:18.396295Z",
     "start_time": "2023-02-24T23:30:56.782832Z"
    }
   },
   "outputs": [],
   "source": [
    "# trasnform sequence features\n",
    "for feature in seq_sparse_feature:\n",
    "    if feature == 'sku_purchase_seq' or feature == 'sku_view_sequence':\n",
    "        df_input[feature] = df_input[feature].apply(lambda x: label_transform(lbe_sku, x))\n",
    "#         df_input[feature] = df_input[feature].apply(lambda x: lbe_sku.transform(x) + 1)\n",
    "\n",
    "    elif feature == 'category_path_purchase_seq':\n",
    "        df_input[feature] = df_input[feature].apply(lambda x: label_transform(lbe_cat, x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-24T23:41:39.904267Z",
     "start_time": "2023-02-24T23:41:39.852978Z"
    }
   },
   "outputs": [],
   "source": [
    "# get feature index table\n",
    "feature_max_idx = {}\n",
    "for feature in sparse_features:\n",
    "    feature_max_idx[feature] = df_input[feature].max() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-24T23:43:42.734034Z",
     "start_time": "2023-02-24T23:43:30.045246Z"
    }
   },
   "outputs": [],
   "source": [
    "df_input.to_csv(\"/Users/LINGYU1/work/localspace/data/mik_dnn_model_02222023/df_input_20230224.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T20:20:07.272709Z",
     "start_time": "2023-04-05T20:18:37.426941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000, 1)                                          random_char\n",
      "0  [d, O, d, v, z, i, w, D, U, k, Y, K, T, k, f, ...\n",
      "1  [J, p, U, Z, N, E, T, y, Z, Z, h, c, F, Q, W, ...\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "# define the character dictionary\n",
    "char_dict = {chr(i): i-65 for i in range(65, 91)}\n",
    "char_dict.update({chr(i): i-71 for i in range(97, 123)})\n",
    "\n",
    "# define a function to generate a random string of uppercase and lowercase English characters\n",
    "def random_string(length):\n",
    "    letters = string.ascii_letters\n",
    "    return ''.join(random.choice(letters) for i in range(length))\n",
    "\n",
    "# create a Pandas DataFrame with a column of 50-length Numpy arrays containing random strings\n",
    "df = pd.DataFrame({'random_char': [np.array([random_string(1) for i in range(50)]) for j in range(1600000)]})\n",
    "\n",
    "# print the resulting DataFrame\n",
    "print(df.shape, df.head(2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dict encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T20:25:44.980407Z",
     "start_time": "2023-04-05T20:25:18.317403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 26.60670518875122 seconds ---\n",
      "(1600000, 2)\n",
      "                                         random_char  \\\n",
      "0  [d, O, d, v, z, i, w, D, U, k, Y, K, T, k, f, ...   \n",
      "1  [J, p, U, Z, N, E, T, y, Z, Z, h, c, F, Q, W, ...   \n",
      "2  [X, S, M, h, d, K, l, y, f, K, x, O, H, S, j, ...   \n",
      "3  [o, G, T, z, g, s, h, I, D, F, l, k, k, b, P, ...   \n",
      "4  [W, J, S, x, X, Q, o, M, h, b, t, W, b, B, T, ...   \n",
      "\n",
      "                                         encode_char  \n",
      "0  [29, 14, 29, 47, 51, 34, 48, 3, 20, 36, 24, 10...  \n",
      "1  [9, 41, 20, 25, 13, 4, 19, 50, 25, 25, 33, 28,...  \n",
      "2  [23, 18, 12, 33, 29, 10, 37, 50, 31, 10, 49, 1...  \n",
      "3  [40, 6, 19, 51, 32, 44, 33, 8, 3, 5, 37, 36, 3...  \n",
      "4  [22, 9, 18, 49, 23, 16, 40, 12, 33, 27, 45, 22...  \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def encode_characters(df, char_dict):\n",
    "    # use the lambda function and the np.apply_along_axis() function to encode all characters in the \"Random Characters\" column\n",
    "    df[\"encode_char\"] = df['random_char'].apply(lambda x: np.array([char_dict[c] for c in x]))\n",
    "    return df\n",
    "\n",
    "start_time = time.time()\n",
    "df = encode_characters(df, char_dict)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T20:25:45.104385Z",
     "start_time": "2023-04-05T20:25:44.984175Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T20:25:45.178053Z",
     "start_time": "2023-04-05T20:25:45.105870Z"
    }
   },
   "outputs": [],
   "source": [
    "lbe = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T20:25:45.227481Z",
     "start_time": "2023-04-05T20:25:45.182188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbe.fit(list(char_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T20:27:21.621435Z",
     "start_time": "2023-04-05T20:25:45.230533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 96.34215307235718 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df['lbe_char'] = df['random_char'].apply(lambda x: lbe.transform(x))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T20:27:21.862261Z",
     "start_time": "2023-04-05T20:27:21.623773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}